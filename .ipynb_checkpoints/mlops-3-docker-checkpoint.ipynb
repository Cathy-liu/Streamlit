{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b523a0d1-404b-4c8f-8ab5-545c4ca7cabd",
   "metadata": {},
   "source": [
    "# Model Deployment on Cloud with Docker\n",
    "- Once we create a Flask API that can run on our local computer, we have everything we need to publish our trained ML model for the whole world to use!\n",
    "- To deploy a Flask API on the internet, we need two things\n",
    "    1. A way to package `inference.py`, our trained ML model, the python libraries that are needed, etc into a format that we can easily deployed to any machine.\n",
    "    1. A machine somewhere on the internet that can continuously keep our `inference.py` running.\n",
    "- ***IMPORTANT!*** We need the trained model from `mlops-1-experiment-tracking.ipynb` and the inference.py from `mlops-2-flask-api.ipynb` notebooks to proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db26b062-2faa-4cf4-9c1e-7c3bd91925d3",
   "metadata": {},
   "source": [
    "# 1. Docker\n",
    "- A way to package `inference.py`, our trained ML model, the python libraries that are needed, etc into a format that we can easily deployed to any machine.\n",
    "- [Docker](https://docs.docker.com/get-docker/) is a container framework heavily used in the software industry to package code and dependencies to run any application. Chances are, every single website you use, is a Docker container running on some machine on the internet.\n",
    "- Docker has 3 simple concepts\n",
    "    - Dockerfile: This is a file written in Docker domain specific language that provides instructions on how to create the Docker image\n",
    "    - Docker image: This is the \"package\" containing all the files and dependencies necessary for the API to run. You can think of Docker image as a template\n",
    "    - Docker container: We can use a docker image to run one or more containers on each machine. Each container uses the Docker image template to create an instance that is running on the machine.\n",
    "    \n",
    "    <img src=\"../images/03_01_Docker_concepts.png\" width=\"1000\">\n",
    "    \n",
    "- There are many ways to deploy ML models, Flask + Docker is just one of them. Some other popular ways are\n",
    "    - AWS Sagemaker\n",
    "    - GCP Vertex AI\n",
    "    - [BentoML](https://www.bentoml.com/)\n",
    "- The biggest advantage of Docker instead of Sagemaker or VertexAI is that once you \"package\" your code as a Docker image, it can run practically everywhere!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867737d9-7cbd-4bf9-b0d3-0c43aba229fc",
   "metadata": {},
   "source": [
    "## Create a Dockerfile\n",
    "- Create a new file called ***EXACTLY*** `Dockerfile`. No extensions, capital 'D'!\n",
    "\n",
    "<img src=\"../images/03_02_Dockerfile.png\" width=\"450\">\n",
    "\n",
    "- For a complete list of all possible Dockerfile commands, see [here](https://docs.docker.com/engine/reference/builder/)\n",
    "- We can also overwrite the `requirements.txt` file in `best_estimator` to only keep the libraries that `inference.py` requires such as `flask` and `pandas` and `mlflow`. We can also replace `mlflow` with `mlflow-skinny` to reduce the size of the image further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741ca20a-95ff-4859-b9a0-9fb44b02cffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "# Use the official lightweight Python image from\n",
    "# https://hub.docker.com/_/python\n",
    "FROM python:3.8-slim\n",
    "\n",
    "# Copy all the files needed for the app to work\n",
    "COPY inference.py .\n",
    "COPY best_estimator/ ./best_estimator\n",
    "\n",
    "# Install all the necessary libraries\n",
    "RUN pip install -r ./best_estimator/requirements.txt\n",
    "\n",
    "# Run the API!\n",
    "CMD python inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7a18228-3c1e-4337-9b48-8d01185e5546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting best_estimator/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile best_estimator/requirements.txt\n",
    "pandas\n",
    "flask\n",
    "mlflow-skinny\n",
    "scikit-learn==1.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f11256-6399-46db-8abd-5e6100c2a813",
   "metadata": {},
   "source": [
    "## Optional: Test the Dockerfile locally\n",
    "- Start up Docker desktop on your computer\n",
    "- Open a new terminal window and navigate to this solution-code directory. You should find the `Dockerfile` that we just created here.\n",
    "- Build the docker image using this Dockerfile by running: `docker build . --tag grad-school-admission:latest`\n",
    "    - --tag: A name for this new Docker image\n",
    "    - Docker naming convention is <name_of_service>:<version>. latest means latest version\n",
    "- Once the docker image has built successfully you can test it out by using it to run a container on your local computer either using the Docker Desktop UI or by running: `docker run -p 8080:8080 --rm grad-school-admission:latest`\n",
    "    - -p 8080:8080 -> map the port 8080 in the docker container to 8080 on your local machine\n",
    "    - --rm -> remove the container when its stopped (optional)\n",
    "    - grad-school-admission:latest -> the name of the image to run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f1b1f-3965-44e5-b720-9060b44d9cd6",
   "metadata": {},
   "source": [
    "# 2. Deploy to Google Cloud Run for free!\n",
    "- A machine somewhere on the internet that can continuously keep our `inference.py` running.\n",
    "- Once you write a Dockerfile for your API, you can use the many many services provided by the various cloud vendors to deploy! \n",
    "- GCP Cloud Run is one of these services that's free for moderate usage [Link](https://cloud.google.com/products/calculator/#id=32ea150c-67b7-4ebc-9143-789f703ee574)\n",
    "\n",
    "<img src=\"../images/03_03_cloud_run_pricing.png\" width=\"350\">\n",
    "\n",
    "When you use GCP for the first time on your local computer, you need to perform some pre-requisite steps:\n",
    "1. Have a GCP account and a project already created\n",
    "1. Open a new terminal window\n",
    "1. Install gcloud SDK from [Link](https://cloud.google.com/sdk/docs/install)\n",
    "1. Initialize gloud SDK: `gcloud init`\n",
    "1. Authenticate your account: `gcloud auth application-default login`\n",
    "\n",
    "To deploy a Dockerfile to GCP Cloud Run:\n",
    "1. Open a new terminal window and navigate to this `solution-code` directory. You should find the `Dockerfile` that we just created here.\n",
    "1. Run: `gcloud run deploy grad-school-admission --source . --region asia-southeast1`\n",
    "1. Type `y` to any message you get and press enter\n",
    "\n",
    "Done! Your API has been deployed on the cloud and is now accessible by everyone on the internet!\n",
    "\n",
    "P.S. If you have a new version of the model or code, you can run the same `gcloud run` command above and the API will get updated to the latest version!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed430e90-acad-4cb4-a675-a641e9a45495",
   "metadata": {},
   "source": [
    "# Test the API\n",
    "- To test out if our API is working, we just need the URL from the Cloud Run page \n",
    "\n",
    "<img src=\"../images/03_04_cloud_run_url.png\" width=\"1000\">\n",
    "\n",
    "- We can interact with any route in the API simply by posting a request to that route. For example, type the URL in your browser and see what you get!\n",
    "- To get predictions, we need to post our input data to the `/predict` route which gets appended at the end of the URL.\n",
    "- Let's load the same data we used to train the model and send the first 5 rows to the API for predictions. The only code difference compared to `mlops-2-flask-api.ipynb` is the `url` parameter. Everything else is exactly the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c656a21-f804-4f37-aac0-66e6fc79d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load some data\n",
    "import pandas as pd\n",
    "admissions = pd.read_csv('../data/grad_admissions.csv')\n",
    "admissions.dropna(inplace=True)\n",
    "\n",
    "# Split X and y\n",
    "X = admissions.drop(columns=['admit']) \n",
    "y = admissions['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6694df32-ef4e-42d8-aef0-90fdf28369ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"gre\":380.0,\"gpa\":2.9150181139}\\n{\"gre\":660.0,\"gpa\":4.0445401188}\\n{\"gre\":800.0,\"gpa\":4.9507143064}\\n{\"gre\":640.0,\"gpa\":3.9219939418}\\n{\"gre\":520.0,\"gpa\":2.0698776028}\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract 5 lines from X to send to the API for predictions\n",
    "# We'll convert the pandas dataframe to a JSON Lines (JSONL) object so it can be sent to the API\n",
    "# We cannot directly send a dataframe over the internet. We can only send JSON over the internet\n",
    "\n",
    "user_input_df = X.head()\n",
    "user_input = user_input_df.to_json(orient=\"records\", lines=True) # convert df to JSONL\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26f3c82-e47a-4085-844d-67380595870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [0, 1, 1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Send the JSONL data as request to the API and print the response\n",
    "import requests\n",
    "\n",
    "api_url = 'https://grad-school-admission-a4rmk57awq-as.a.run.app'\n",
    "api_route = '/predict'\n",
    "\n",
    "response = requests.post(f'{api_url}{api_route}', json=user_input)\n",
    "predictions = response.json()\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4b5e9-b897-4417-bd60-1562e289fc41",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "- GCP Cloud Run is practically free so you can let your API continue to run\n",
    "- If you want to delete everything\n",
    "    1. Delete the API from GCP Cloud Run \n",
    "    1. Delete the docker image from GCP Artifact Registry\n",
    "    1. Delete any Cloud Storage buckets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843a65dc-5120-4152-b4b8-18e49aef1642",
   "metadata": {},
   "source": [
    "# Bonus! Easy Steps to become a Millionaire\n",
    "1. Invent a fancy API\n",
    "1. Wrap it into a Docker container\n",
    "1. Host it in GCP Cloud Run\n",
    "1. Publish it on [RapidAPI](https://rapidapi.com/) to easily sell access to it!!! Check out [Leo's Name-Gender prediction API](https://rapidapi.com/stephenleo87-DGFI1at-XQ/api/name-gender1/)\n",
    "1. Become a Millionaire!\n",
    "\n",
    "![](../images/03_05_make-it-rain-meme.jpeg)\n",
    "\n",
    "Read more about it in detail on Leo's Medium blog post: [Make extra money on the side with data science](https://pub.towardsai.net/make-extra-money-on-the-side-with-data-science-984a623c53f5?sk=31e1a7794b073841e9ed66eeb1cc8867)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c974d29-1789-48cf-9397-63779f3d1d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
