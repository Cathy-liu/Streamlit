{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60c3fc2-f7dd-45ca-a887-68e715cab322",
   "metadata": {},
   "source": [
    "# Model Deployment with Flask\n",
    "- [Flask](https://flask.palletsprojects.com/en/2.2.x/) and [FastAPI](https://fastapi.tiangolo.com/) are two python libraries that allow us to create our own APIs\n",
    "- Flask is older but probably more widely used. FastAPI is newer and is very fast but has a small learning curve. Many concepts are similar between them\n",
    "- APIs work on the concept of `route`.\n",
    "    - A `route` is an address in an API. It can accept some inputs called `requests` and returns some output `response`\n",
    "    - A single API can contain multiple `routes`\n",
    "    - All the routes inside the same API can be accessed using the same URL with the route name appended to the end of the URL as shown below\n",
    "    ![](../images/02_01_anatomy_of_api.png)\n",
    "- We can open up a way for others to interact with our trained ML model using Flask. The users would only need to provide inputs in the JSON format (python dictionary) and will get outputs also in JSON format\n",
    "\n",
    "***IMPORTANT!*** We need the trained model from `mlops-1-experiment-tracking.ipynb` notebook to proceed with below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b2466b-8f7a-453b-8d49-1595221b28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the Flask library is installed\n",
    "# !pip install -U Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c5479-a954-4527-adee-1cd5cf0995be",
   "metadata": {},
   "source": [
    "# Create an inference.py file\n",
    "There are a few simple steps to create the Flask API\n",
    "1. Create a new Python script. You can call it anything, we'll name is `inference.py` since we're going to use it to run our model inference\n",
    "1. Instantiate the Flask API using the `Flask()` class and give it a name\n",
    "1. Load the model\n",
    "1. Create all the routes you want. Each route is just a Python function with a decorator to expose that function as a Flask API. Minimally you'd have atleast one route that accepts the user inputs, runs model predictions on these inputs and returns the predictions as output.\n",
    "1. Run the API in the main block of the Python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79c2344b-0d6d-47bf-b72e-4dac71c60295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "from flask import Flask, request\n",
    "import pandas as pd\n",
    "import os\n",
    "import mlflow.pyfunc\n",
    "\n",
    "# Step 2: Instantiate the Flask API\n",
    "api = Flask('ModelEndpoint')\n",
    "\n",
    "# Step 3: Load the model\n",
    "model = mlflow.pyfunc.load_model(model_uri=\"./best_estimator\")\n",
    "\n",
    "# Step 4: Create the routes\n",
    "## route 1: Health check. Just return success if the API is running\n",
    "@api.route('/')\n",
    "def home():\n",
    "    # return a simple string\n",
    "    return {\"message\": \"Hi there!\", \"success\": True}, 200\n",
    "\n",
    "# route 2: accept input data\n",
    "# Post method is used when we want to receive some data from the user\n",
    "@api.route('/predict', methods = ['POST'])\n",
    "def make_predictions():\n",
    "    # Get the data sent over the API\n",
    "    user_input = request.get_json(force=True)\n",
    "    \n",
    "    # Convert user inputs to pandas dataframe\n",
    "    df_schema = {\"gre\":float, \"gpa\": float} # To ensure the columns get the correct datatype\n",
    "    user_input_df = pd.read_json(user_input, lines=True, dtype=df_schema) # Convert JSONL to dataframe\n",
    "    \n",
    "    # Run predictions and convert to list\n",
    "    predictions = model.predict(user_input_df).tolist()\n",
    "    \n",
    "    return {'predictions': predictions}\n",
    "    \n",
    "\n",
    "# Step 5: Main function that actually runs the API!\n",
    "if __name__ == '__main__':\n",
    "    api.run(host='0.0.0.0', \n",
    "            debug=True, # Debug=True ensures any changes to inference.py automatically updates the running API\n",
    "            port=int(os.environ.get(\"PORT\", 8080))\n",
    "           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72558c2-9898-4518-accd-998543a4aab7",
   "metadata": {},
   "source": [
    "# Test the API\n",
    "- To test out if our API is working, we first need to run the API code `inference.py`\n",
    "- Open a new terminal window and navigate to this `solution-code` directory. You should find the `inference.py` file that we just created here.\n",
    "- Run the file as a normal python file: `python inference.py`\n",
    "- Now your API is running on your local computer and is ready to accept input data at `http://localhost:8080` URL\n",
    "- We can interact with any route in the API simply by posting a request to that route. For example, type `http://localhost:8080/` in your browser and see what you get!\n",
    "- To get predictions, we need to post our input data to the `/predict` route which gets appended at the end of the URL. So the URL will become `http://localhost:8080/predict`\n",
    "- Let's load the same data we used to train the model and send the first 5 rows to the API for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea296e2-9103-4597-bbf8-a8f4878e9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data\n",
    "import pandas as pd\n",
    "admissions = pd.read_csv('../data/grad_admissions.csv')\n",
    "admissions.dropna(inplace=True)\n",
    "\n",
    "# Split X and y\n",
    "X = admissions.drop(columns=['admit']) \n",
    "y = admissions['admit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a350bdf-a164-45cf-944c-f00bfff5ac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"gre\":380.0,\"gpa\":2.9150181139}\\n{\"gre\":660.0,\"gpa\":4.0445401188}\\n{\"gre\":800.0,\"gpa\":4.9507143064}\\n{\"gre\":640.0,\"gpa\":3.9219939418}\\n{\"gre\":520.0,\"gpa\":2.0698776028}\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract 5 lines from X to send to the API for predictions\n",
    "# We'll convert the pandas dataframe to a JSON Lines (JSONL) object so it can be sent to the API\n",
    "# We cannot directly send a dataframe over the internet. We can only send JSON over the internet\n",
    "\n",
    "user_input_df = X.head()\n",
    "user_input = user_input_df.to_json(orient=\"records\", lines=True) # convert df to JSONL\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9da06c-3f18-4730-8b7a-032fbc8b2ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [0, 1, 1, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Send the JSONL data as request to the API and print the response\n",
    "import requests\n",
    "\n",
    "api_url = 'http://localhost:8080'\n",
    "api_route = '/predict'\n",
    "\n",
    "response = requests.post(f'{api_url}{api_route}', json=user_input)\n",
    "predictions = response.json()\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d18ff2-6dd3-4124-b1a7-f1e2188af5ee",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "\n",
    "## To stop and restart the Flask API\n",
    "- To stop the Flask API, press `Ctrl + C` in the terminal window that's running the API.\n",
    "- You can restart the Flask API ***IN THE SAME FOLDER*** by running `python inference.py` again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800b00c-2429-4d7c-84c1-7a4ef22121ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
